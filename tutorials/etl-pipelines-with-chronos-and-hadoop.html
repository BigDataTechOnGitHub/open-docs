---
redirect_from:
  - /learn/etl-pipelines-with-chronos-and-hadoop/
layout: tutorial
title: Build ETL Pipelines with Chronos and Hadoop
tutorial_icon_classname: tutorial-icon-chronos
framework: chronos
tutorial_name: etl-pipelines-with-chronos-and-hadoop
overview: Introduction and prerequisites for how to use Chronos to schedule an ETL pipeline
steps:
  - title: Setup the cluster
    blurb: >
      Prepare your cluster by copying the Hadoop distribution to each host
    icon: fa-wrench
    blackboard: >
      <pre class="terminal"><code>ubuntu@ec2-23-20-63-14:~$ servers=(<span data-replace="slave-external-ip-list">slave1.example.com slave2.example.com slave3.example.com</span>); for s in "${servers[@]}"; do ssh -l ubuntu $s 'sudo sh -c "cd /tmp &amp;&amp; hadoop fs -get /hadoop-2.0.0-mr1-cdh4.2.1.tgz &amp;&amp; tar xzf hadoop-2.0.0-mr1-cdh4.2.1.tgz &amp;&amp; mkdir -p /opt/mesos/ &amp;&amp; mv hadoop-2.0.0-mr1-cdh4.2.1 /opt/mesos/hadoop &amp;&amp; echo $s DONE"' ; done

      The authenticity of host '67.202.20.129 (67.202.20.129)' can't be established.

      ECDSA key fingerprint is 02:39:74:e9:73:f6:8d:d1:00:ff:30:e7:01:de:7c:ed.

      Are you sure you want to continue connecting (yes/no)? yes

      Warning: Permanently added '67.202.20.129' (ECDSA) to the list of known hosts.

      The authenticity of host '23.20.77.5 (23.20.77.5)' can't be established.

      ECDSA key fingerprint is 96:bf:0d:6b:10:00:c4:a2:d6:50:76:e6:8a:c3:0b:a1.

      Are you sure you want to continue connecting (yes/no)? yes

      Warning: Permanently added '23.20.77.5' (ECDSA) to the list of known hosts.

      The authenticity of host '23.20.253.243 (23.20.253.243)' can't be established.

      ECDSA key fingerprint is 2b:ec:59:8b:96:56:5d:8d:50:62:5c:67:f1:bc:c3:c0.

      Are you sure you want to continue connecting (yes/no)? yes

      Warning: Permanently added '23.20.253.243' (ECDSA) to the list of known hosts.</code></pre>
    instruction: >
      <p>In this tutorial, you'll learn how to leverage Chronos and Hadoop to setup a typical <a href="https://en.wikipedia.org/wiki/Extract,_transform,_load">ETL</a> pipeline. It consists of three steps: step 1 downloads the Enron email corpus and stores it in HDFS. Step 2 runs the Hadoop word count example on it. Step 3 fetches the word count output from HDFS and prints it out.</p>
      <p>The tutorial assumes that you completed the <a href="/tutorials/run-chronos-on-mesos/">Chronos</a> and <a href="/tutorials/run-hadoop-on-mesos/">Hadoop</a> tutorials and requires a Hadoop distribution with Mesos support. The Hadoop tutorial explains how to build a compatible distribution.</p>
      <p>You will need a running Mesos cluster with Hadoop available on all slave nodes. If you followed the Hadoop tutorial and are using Elastic Mesos, run this command in your local terminal to copy the Hadoop distribution from HDFS to all the Mesos slave nodes:</p>
      <pre data-code><code class="codeblock">servers=(<span data-replace="slave-external-ip-list">slave1.example.com slave2.example.com slave3.example.com</span>); for s in "${servers[@]}"; do ssh -l ubuntu $s 'sudo sh -c "cd /tmp &amp;&amp; hadoop fs -get /hadoop-2.0.0-mr1-cdh4.2.1.tgz &amp;&amp; tar xzf hadoop-2.0.0-mr1-cdh4.2.1.tgz &amp;&amp; mkdir -p /opt/mesos/ &amp;&amp; mv hadoop-2.0.0-mr1-cdh4.2.1 /opt/mesos/hadoop"' ; done</code></pre>
      <p>Adjust the command accordingly if you're using your own Hadoop on Mesos cluster.</p>
  - title: Create first Chronos job
    blurb: >
      Create the job to download the raw enron data
    icon: fa-rocket
    blackboard: >
      <span data-img-placeholder
        data-alt=""
        data-class="thumbnail img-responsive"
        data-src="{% asset_path learn/chronos_hadoop_00_download_enron.jpg %}"></span>
    instruction: >
      <p>Next, navigate to the Chronos web UI at <code>http://<span data-replace="master-ip">your-chronos-host.example.com</span>:8080</code> and create a job that runs the following command to download the Enron corpus and put it in HDFS under <code>/enron</code>:</p>
      <pre data-code><code class="codeblock">curl -sS http://bailando.sims.berkeley.edu/enron/enron_with_categories.tar.gz | tar xzv &amp;&amp; sudo -u mapred /opt/mesos/hadoop/bin/hadoop fs -mkdir /enron &amp;&amp; sudo -u mapred /opt/mesos/hadoop/bin/hadoop fs -put enron_with_categories/*/*.txt /enron</code></pre>
      <p>Name the job <em>download_enron</em> and enter your email address under <em>OWNER(S)</em>. Schedule the job to run a few minutes from now so you have enough time to complete the next steps.</p>
  - title: Create a dependent Chronos job
    blurb: >
      Create the chronos job that triggers a Hadoop run
    icon: fa-plus
    blackboard: >
      <span data-img-placeholder
        data-alt=""
        data-class="thumbnail img-responsive"
        data-src="{% asset_path learn/chronos_hadoop_01_wordcount.jpg %}"></span>
    instruction: >
      <p>Next, let's create a Chronos job that runs the Hadoop wordcount example on the Enron data set. Create a new job that runs the following command:</p>
      <pre data-code><code class="codeblock">sudo -u mapred /opt/mesos/hadoop/bin/hadoop jar /opt/mesos/hadoop/hadoop-examples-2.0.0-mr1-cdh4.2.1.jar wordcount /enron /enron_wordcount</code></pre>
      <p>Name the job <em>wordcount</em> and select <em>download_enron</em> as the parent. This will ensure that wordcount only runs if <em>download_enron</em> ran successfully. Enter your email address as the owner.</p>
      <p>The wordcount job will write its output to the <code>/enron_wordcount</code> path in HDFS.</p>
  - title: Create Chronos job that outputs the results
    blurb: >
      This Chronos job will output the result data to the task sandbox which can be viewed in the Mesos UI
    icon: fa-list-ul
    blackboard: >
      <span data-img-placeholder
        data-alt=""
        data-class="thumbnail img-responsive"
        data-src="{% asset_path learn/chronos_hadoop_02_output.jpg %}"></span>
    instruction: >
      <p>Let's create the final job in our pipeline that is just going to print the output from wordcount so we can look at it in the Mesos UI. Add a new Chronos job that runs the following command:</p>
      <pre data-code><code class="codeblock">sudo -u mapred /opt/mesos/hadoop/bin/hadoop fs -cat /enron_wordcount/part-* | sort -rnk2 | head -20</code></pre>
      <p>Name the job <em>output</em> and select <em>wordcount</em> as the parent. Again, put in your email address as the owner.</p>
  - title: Checkout the Dependency Graph
    blurb: >
      Explore the dependency graph feature in Chronos by visualizing the job graph
    icon: fa-bar-chart-o
    blackboard: >
      <span data-img-placeholder
        data-alt=""
        data-class="thumbnail img-responsive"
        data-src="{% asset_path learn/chronos_hadoop_04_jobs_graph.jpg %}"></span>
    instruction: >
      <p>You should now see three jobs in the Chronos job list. Click on the <em>Dependency Graph</em> button to verify that they're connected properly. You can close the graph again by clicking the X.</p>
  - title: Chronos Overview
    blurb: >
      See the updates on the Chronos page as the jobs run
    icon: fa-list-alt
    blackboard: >
      <span data-img-placeholder
        data-alt=""
        data-class="thumbnail img-responsive"
        data-src="{% asset_path learn/chronos_hadoop_05_success.jpg %}"></span>
    instruction: >
      <p>Your pipeline should start running at the time you entered in the first step, and the jobs should change their status to <em>success</em> one by one. The pipeline will take a few minutes to run, depending on your cluster size. The nodes in the graph view will turn green to mark success.</p>
  - title: Explore the Mesos UI
    blurb: >
      Look at the task list in the Mesos UI to see if everything work
    icon: fa-list-ul
    blackboard: >
      <span data-img-placeholder
        data-alt=""
        data-class="thumbnail img-responsive"
        data-src="{% asset_path learn/chronos_hadoop_06_mesos_web.jpg %}"></span>
    instruction: >
      <p>Lastly, let's use the Mesos web UI to look at the output of our pipeline. Open the web UI at <code>http://<span data-replace="master-ip">your-mesos-master.example.com</span>:5050</code>, navigate to <em>Frameworks</em>, select <em>chronos-2.0.1</em>, and find the task named <em>ChronosTask:output</em> in the <em>Completed Tasks</em> section. Click on the <em>Sandbox</em> link next to it and then the <em>stdout</em> link.</p>
  - title: Explore Output
    blurb: >
      Look at the task output to see the results of the job pipeline
    icon: fa-list
    blackboard: >
      <span data-img-placeholder
        data-alt=""
        data-class="thumbnail img-responsive"
        data-src="{% asset_path learn/chronos_hadoop_07_pailer.jpg %}"></span>
    instruction: >
      <p>As you can see the most frequent words in this corpus are common English words like the definite article and some prepositions, but the word <em>power</em> shows up as well.</p>
success:
  title: Next steps
  blurb: >
    A slightly more detailed description for what happens in this step of the tutorial
  text: >
    <p>Congratulations! You just ran your first ETL pipeline with Chronos and Hadoop.</p>
---
